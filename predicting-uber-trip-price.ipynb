{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1  align ='center'> Predicting Price of uber trip </h1>\n\n<h3 align = 'center'> Version 14  </h3>","metadata":{"papermill":{"duration":0.07811,"end_time":"2021-11-21T11:15:50.903499","exception":false,"start_time":"2021-11-21T11:15:50.825389","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Introduction\n- This is a project for predicting Uber trip price. As usual, the dataset we have is noisy and needs lots of feature engineering, and preprocessing.\n- Now let's start working on a dataset in the Notebook. The first step is to import the libraries and load data. After that we will take a basic understanding of data like its shape, sample, is there are any NULL values present in the dataset. Understanding the data is an important step for prediction or any machine learning project.","metadata":{}},{"cell_type":"markdown","source":"## Project Agenda\n- 1- Introduction\n- 2- Load the Data\n- 3- Data Assessing\n- 4- Data Cleaning\n- 5- Perfrom Exploratory Data Analysis\n- 6- Feature Engineering\n- 7- Model Selection \n- 8- Tesing The Selected Model\n","metadata":{"papermill":{"duration":0.06606,"end_time":"2021-11-21T11:15:51.060771","exception":false,"start_time":"2021-11-21T11:15:50.994711","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 2- Loading the Data","metadata":{"papermill":{"duration":0.068043,"end_time":"2021-11-21T11:15:51.327135","exception":false,"start_time":"2021-11-21T11:15:51.259092","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#port Necessary libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn import ensemble\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option(\"display.max_columns\", None)\nuber_df = pd.read_csv(r\"../input/historicaluberdata/UberDataSet.csv\")","metadata":{"papermill":{"duration":2.699531,"end_time":"2021-11-21T11:15:54.157038","exception":false,"start_time":"2021-11-21T11:15:51.457507","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3- Data Assessing \n__________________________________________________\n- Data assessing is the step in which we evaluate our data.\n### In this step:\n- We take a quick look inside our data and the columns.\n- Check if there are any missing values in the data so that we can handle them.\n- Check if there are duplicated values.\n","metadata":{"id":"N-viUF78dM1P","papermill":{"duration":0.072523,"end_time":"2021-11-21T11:16:00.253054","exception":false,"start_time":"2021-11-21T11:16:00.180531","status":"completed"},"tags":[]}},{"cell_type":"code","source":"uber_df.head(5)","metadata":{"id":"CiH0o0t3dM1P","outputId":"ad22cc1e-e136-4ec1-8a7f-ba83c7e801a8","papermill":{"duration":0.148622,"end_time":"2021-11-21T11:16:00.47491","exception":false,"start_time":"2021-11-21T11:16:00.326288","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.info()","metadata":{"papermill":{"duration":0.52476,"end_time":"2021-11-21T11:16:01.070552","exception":false,"start_time":"2021-11-21T11:16:00.545792","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.isnull().sum()","metadata":{"id":"G79HQLtXdM1W","outputId":"db1e3ce5-826c-4451-fe6d-a2f1a9e69a34","papermill":{"duration":0.495723,"end_time":"2021-11-21T11:16:01.636816","exception":false,"start_time":"2021-11-21T11:16:01.141093","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.columns","metadata":{"papermill":{"duration":0.078481,"end_time":"2021-11-21T11:16:01.786359","exception":false,"start_time":"2021-11-21T11:16:01.707878","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df['cab_type'].value_counts()","metadata":{"papermill":{"duration":0.159631,"end_time":"2021-11-21T11:16:02.016354","exception":false,"start_time":"2021-11-21T11:16:01.856723","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.product_id.value_counts()","metadata":{"papermill":{"duration":0.134103,"end_time":"2021-11-21T11:16:02.223058","exception":false,"start_time":"2021-11-21T11:16:02.088955","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df['name'].value_counts()","metadata":{"papermill":{"duration":0.13761,"end_time":"2021-11-21T11:16:02.432394","exception":false,"start_time":"2021-11-21T11:16:02.294784","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.shape","metadata":{"papermill":{"duration":0.08624,"end_time":"2021-11-21T11:16:02.592296","exception":false,"start_time":"2021-11-21T11:16:02.506056","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.duplicated().sum()","metadata":{"papermill":{"duration":1.448391,"end_time":"2021-11-21T11:16:04.11413","exception":false,"start_time":"2021-11-21T11:16:02.665739","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Data Cleaning\n- We must drop   ('Unnamed: 0','DateTime','id','product_id','long_summary','short_summary','timestamp' ) Columns  because we don't need them\n- Fix Missing Values in price column by Droping missing values in price column\n- Change icon and name Columns name to Weather and Uber Service Type\n","metadata":{"papermill":{"duration":0.072162,"end_time":"2021-11-21T11:16:04.258552","exception":false,"start_time":"2021-11-21T11:16:04.18639","status":"completed"},"tags":[]}},{"cell_type":"code","source":"uber_df.dropna(inplace=True)\n#since we have one timezone so i will delete it  which America/New_York and also for cab_type since we have only uber \nuber_df.timezone.value_counts()","metadata":{"papermill":{"duration":0.583961,"end_time":"2021-11-21T11:16:04.914372","exception":false,"start_time":"2021-11-21T11:16:04.330411","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removeing  'latitude', 'longitude','source', 'destination','datetime','Unnamed: 0','index','id','product_id','long_summary','short_summary','timestamp','timezone','cab_type' Columns \nuber_df=uber_df.reset_index()\nuber_df = uber_df.drop(['latitude', 'longitude','source', 'destination','datetime','Unnamed: 0','index','id','product_id','long_summary','short_summary','timestamp','timezone','cab_type'], axis=1 )\nuber_df.info()","metadata":{"papermill":{"duration":0.435864,"end_time":"2021-11-21T11:16:05.781291","exception":false,"start_time":"2021-11-21T11:16:05.345427","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.shape","metadata":{"papermill":{"duration":0.081507,"end_time":"2021-11-21T11:16:05.938211","exception":false,"start_time":"2021-11-21T11:16:05.856704","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change icon and name Columns name to Weather and Uber Service Type\nuber_df.rename(columns={'name': 'service_type','icon':'weather_condition'}, inplace=True)\nuber_df.head(2)","metadata":{"papermill":{"duration":0.087852,"end_time":"2021-11-21T11:16:06.098115","exception":false,"start_time":"2021-11-21T11:16:06.010263","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.info()","metadata":{"papermill":{"duration":0.246735,"end_time":"2021-11-21T11:16:06.619121","exception":false,"start_time":"2021-11-21T11:16:06.372386","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.to_csv(r'CleanAndFilteredData.csv')\n","metadata":{"papermill":{"duration":13.291961,"end_time":"2021-11-21T11:16:20.353207","exception":false,"start_time":"2021-11-21T11:16:07.061246","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5 - Perform EDA(Exploratory Data Analysis)\n- Exploratory analysis is a process to explore and understand the data and data relationship in a complete depth so that it makes feature engineering and machine learning modeling steps smooth and streamlined for prediction.\n\n","metadata":{"papermill":{"duration":0.087821,"end_time":"2021-11-21T11:16:20.519374","exception":false,"start_time":"2021-11-21T11:16:20.431553","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sns.distplot(uber_df['price'])","metadata":{"papermill":{"duration":2.176847,"end_time":"2021-11-21T11:16:22.823959","exception":false,"start_time":"2021-11-21T11:16:20.647112","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x='service_type', y='price', data=uber_df)","metadata":{"papermill":{"duration":4.047904,"end_time":"2021-11-21T11:16:26.955349","exception":false,"start_time":"2021-11-21T11:16:22.907445","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df['month'].value_counts().plot(kind='bar', figsize=(6,5), color=['#002080','#ff0066'],title = \"Number of trips per Month \")","metadata":{"papermill":{"duration":0.346544,"end_time":"2021-11-21T11:16:27.383248","exception":false,"start_time":"2021-11-21T11:16:27.036704","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Great We have data For two months that is November and December","metadata":{"papermill":{"duration":0.080272,"end_time":"2021-11-21T11:16:27.543493","exception":false,"start_time":"2021-11-21T11:16:27.463221","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pie_df = uber_df.weather_condition.value_counts().reset_index()\npie_df.columns = ['condition', 'count']\n# pie_df.head()\nfig = px.pie(pie_df, values='count', names='condition', title='The proportion of number of trips in each weather condition', color_discrete_sequence=['#003f5c','#ffa600','#bc5090'], hole=0.2)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6- Feature Engineering\n-----------------------------------------------------\n\nWhat is a feature and why we need the engineering of it? Basically, all machine learning algorithms use some input data to create outputs. This input data comprise features, which are usually in the form of structured columns. Algorithms require features with some specific characteristic to work properly. Here, the need for feature engineering arises. \n\nI think feature engineering efforts mainly have two goals:\n\n1) Preparing the proper input dataset, compatible with the machine learning algorithm requirements.\n\n2) Improving the performance of machine learning models.","metadata":{"id":"byuNn6SDdM1X","papermill":{"duration":0.081753,"end_time":"2021-11-21T11:16:28.199949","exception":false,"start_time":"2021-11-21T11:16:28.118196","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 6.1-  Encoding Pandas Get dummy ","metadata":{"id":"JXZS2rP2dM1b","papermill":{"duration":0.080384,"end_time":"2021-11-21T11:16:28.364877","exception":false,"start_time":"2021-11-21T11:16:28.284493","status":"completed"},"tags":[]}},{"cell_type":"code","source":"uber_df.head(1)","metadata":{"papermill":{"duration":0.130494,"end_time":"2021-11-21T11:16:28.576464","exception":false,"start_time":"2021-11-21T11:16:28.44597","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.service_type.value_counts()","metadata":{"papermill":{"duration":0.146431,"end_time":"2021-11-21T11:16:29.506271","exception":false,"start_time":"2021-11-21T11:16:29.35984","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df = pd.get_dummies(uber_df,drop_first=False)","metadata":{"papermill":{"duration":0.382158,"end_time":"2021-11-21T11:16:29.975475","exception":false,"start_time":"2021-11-21T11:16:29.593317","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.head()","metadata":{"papermill":{"duration":0.164627,"end_time":"2021-11-21T11:16:30.22831","exception":false,"start_time":"2021-11-21T11:16:30.063683","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_df.shape","metadata":{"papermill":{"duration":0.099105,"end_time":"2021-11-21T11:16:30.416249","exception":false,"start_time":"2021-11-21T11:16:30.317144","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2- RFE (Recursive Feature Elimination) And R squared \n--------------------------------------\n- Recursive Feature Elimination, or RFE for short, is a popular feature selection algorithm.\n\n- RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are  more or most relevant in predicting the target variable.\n\n- RFE is divided into three parts; they are:\n\n- Recursive Feature Elimination\n- RFE With scikit-learn\n    - RFE for Classification\n    - RFE for Regression\n- RFE Hyperparameters\n   -  Explore Number of Features\n    - Automatically Select the Number of Features\n    - Which Features Were Selected\n   -  Explore Base Algorithm\n   \n   \n   \n - R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Whereas correlation explains the strength of the relationship between an independent and dependent variable, R-squared explains to what extent the variance of one variable explains the variance of the second variable. So, if the R2 of a model is 0.50, then approximately half of the observed variation can be explained by the model's inputs.","metadata":{"id":"U5UVpEBndM1d","papermill":{"duration":0.091301,"end_time":"2021-11-21T11:16:30.595501","exception":false,"start_time":"2021-11-21T11:16:30.5042","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 6.2.1- Load the necessary libraries","metadata":{"papermill":{"duration":0.084602,"end_time":"2021-11-21T11:16:30.767665","exception":false,"start_time":"2021-11-21T11:16:30.683063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import RFE","metadata":{"id":"phS20dKJdM1d","papermill":{"duration":0.109482,"end_time":"2021-11-21T11:16:30.961511","exception":false,"start_time":"2021-11-21T11:16:30.852029","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2.2- Define Dependent Variable 'y', independent variable 'X'  and dictionary of R_sqaured ","metadata":{"papermill":{"duration":0.084481,"end_time":"2021-11-21T11:16:31.134007","exception":false,"start_time":"2021-11-21T11:16:31.049526","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define Dependent Variable 'y'and independent variable 'X'\nX = uber_df.drop('price', axis= 1)\ny = uber_df['price']\nprint(X.shape)\nprint(y.shape)\nR_sqaured = {}\nMean_SE = {}","metadata":{"id":"PKmO97t6dM1d","papermill":{"duration":0.277418,"end_time":"2021-11-21T11:16:31.50087","exception":false,"start_time":"2021-11-21T11:16:31.223452","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RFE (Recursive Feature Elimination) Function","metadata":{"papermill":{"duration":0.092042,"end_time":"2021-11-21T11:16:31.682454","exception":false,"start_time":"2021-11-21T11:16:31.590412","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#ٍSplitting data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n\ndef RFE_Function(i):\n    reg = LinearRegression()\n    rfe = RFE(reg , n_features_to_select = i)\n    rfe = rfe.fit(X_train, y_train)\n    selected_columns = X_train[X_train.columns[rfe.support_]]\n    #Fitting training data\n    reg = reg.fit(selected_columns, y_train)\n    R_sqaured['Feature_'+str(i)]=reg.score(X_test[selected_columns.columns], y_test)\n    y_pred = reg.predict(X_test[selected_columns.columns])\n    Mean_SE['Feature_'+str(i)] = metrics.mean_squared_error(y_test,y_pred)\n    return selected_columns ","metadata":{"papermill":{"duration":0.1003,"end_time":"2021-11-21T11:16:32.308434","exception":false,"start_time":"2021-11-21T11:16:32.208134","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 0 With All features ","metadata":{}},{"cell_type":"code","source":"X_55 = RFE_Function(55)\nprint(\"The R squared of 55 feature is \",R_sqaured['Feature_55'])\nprint(\"The MSE of 55 feature is \",Mean_SE['Feature_55'])\nprint(X_55.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 1: with 48 features \n","metadata":{"papermill":{"duration":0.088052,"end_time":"2021-11-21T11:16:32.481979","exception":false,"start_time":"2021-11-21T11:16:32.393927","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_48 = RFE_Function(48)\nprint(\"The R squared of 48 feature is \",R_sqaured['Feature_48'])\nprint(\"The MSE of 48 feature is \",Mean_SE['Feature_48'])\nprint(X_48.shape)","metadata":{"papermill":{"duration":3.509729,"end_time":"2021-11-21T11:16:36.07951","exception":false,"start_time":"2021-11-21T11:16:32.569781","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 2: with 28 features using RFE","metadata":{"papermill":{"duration":0.085346,"end_time":"2021-11-21T11:16:36.305174","exception":false,"start_time":"2021-11-21T11:16:36.219828","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_28 = RFE_Function(28)\nprint(\"The R squared of 28 feature is \",R_sqaured['Feature_28'])\nprint(\"The MSE of 28 feature is \",Mean_SE['Feature_28'])\nprint(X_28.shape)","metadata":{"papermill":{"duration":27.881216,"end_time":"2021-11-21T11:17:04.273645","exception":false,"start_time":"2021-11-21T11:16:36.392429","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 3: with 18 features using RFE","metadata":{"papermill":{"duration":0.091075,"end_time":"2021-11-21T11:17:04.512679","exception":false,"start_time":"2021-11-21T11:17:04.421604","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_18= RFE_Function(18)\nprint(\"The R squared of 18 feature is \",R_sqaured['Feature_18'])\nprint(\"The MSE of 18 feature is \",Mean_SE['Feature_18'])\nprint(X_18.shape)","metadata":{"papermill":{"duration":41.42325,"end_time":"2021-11-21T11:17:46.030296","exception":false,"start_time":"2021-11-21T11:17:04.607046","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 4: with 8 features using RFE","metadata":{"papermill":{"duration":0.108181,"end_time":"2021-11-21T11:17:46.301447","exception":false,"start_time":"2021-11-21T11:17:46.193266","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_8= RFE_Function(8)\nprint(\"The R squared of 8 feature is \",R_sqaured['Feature_8'])\nprint(\"The MSE of 8 feature is \",Mean_SE['Feature_8'])\nprint(X_8.shape)","metadata":{"papermill":{"duration":45.772735,"end_time":"2021-11-21T11:18:32.182223","exception":false,"start_time":"2021-11-21T11:17:46.409488","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 5: with 5 features using RFE","metadata":{"papermill":{"duration":0.133724,"end_time":"2021-11-21T11:18:32.492245","exception":false,"start_time":"2021-11-21T11:18:32.358521","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X_5= RFE_Function(5)\nprint(\"The R squared of 5 feature is \",R_sqaured['Feature_5'])\nprint(\"The MSE of 5 feature is \",Mean_SE['Feature_5'])\nprint(X_5.shape)","metadata":{"papermill":{"duration":48.487917,"end_time":"2021-11-21T11:19:21.173149","exception":false,"start_time":"2021-11-21T11:18:32.685232","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"R_sqaured","metadata":{"papermill":{"duration":0.199858,"end_time":"2021-11-21T11:21:03.305014","exception":false,"start_time":"2021-11-21T11:21:03.105156","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mean_SE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Chosing number of features \n* As the percentages are close to accuracy, which is 91 % , except when applying RFE with 5 Features  give us 80% , so I will choose training with 8 features. and MSE Also The same As the Value are close to 5.8 except when applying  RFE with 5 Features  give us 14.2","metadata":{}},{"cell_type":"markdown","source":"* It is clear from the differences that there is nothing influential other than the type of car and the distance so we will go with X_8","metadata":{}},{"cell_type":"code","source":"X_8.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_8.drop(['temperatureMax'],axis= 1,inplace=True)\nX_8.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_8\nX_test = X_test[X_8.columns]\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"papermill":{"duration":0.204736,"end_time":"2021-11-21T11:21:04.479045","exception":false,"start_time":"2021-11-21T11:21:04.274309","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7- Model Selection","metadata":{"papermill":{"duration":0.192017,"end_time":"2021-11-21T11:21:05.261645","exception":false,"start_time":"2021-11-21T11:21:05.069628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"papermill":{"duration":0.202018,"end_time":"2021-11-21T11:21:05.65787","exception":false,"start_time":"2021-11-21T11:21:05.455852","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.1 Linear Regression Model ","metadata":{"papermill":{"duration":0.190942,"end_time":"2021-11-21T11:21:06.041485","exception":false,"start_time":"2021-11-21T11:21:05.850543","status":"completed"},"tags":[]}},{"cell_type":"code","source":"linear = LinearRegression()\nlinear.fit(X_train, y_train)\nprint(linear.score(X_test, y_test))\ny_pred = linear.predict(X_test)\nprint('MSE :',\" \", metrics.mean_squared_error(y_test,y_pred))\nprint('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))","metadata":{"papermill":{"duration":0.277221,"end_time":"2021-11-21T11:21:06.512746","exception":false,"start_time":"2021-11-21T11:21:06.235525","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(y_pred, color=\"green\", label='Predicted values') # Linear Regression Model prediction\nsns.kdeplot(y_test, color=\"red\", label='Actual values')\nplt.title(\"Relation between Predicted and Actual value (Linear Regression Model Model)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.3 Random Forest Regressor","metadata":{"papermill":{"duration":0.196617,"end_time":"2021-11-21T11:21:08.033083","exception":false,"start_time":"2021-11-21T11:21:07.836466","status":"completed"},"tags":[]}},{"cell_type":"code","source":"random = RandomForestRegressor(n_estimators = 100, random_state = 0) \nrandom.fit(X_train, y_train) \nprint(random.score(X_test, y_test))\ny_pred = random.predict(X_test)\nprint('MSE :',\" \", metrics.mean_squared_error(y_test,y_pred))\nprint('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))","metadata":{"papermill":{"duration":20.206833,"end_time":"2021-11-21T11:21:28.441746","exception":false,"start_time":"2021-11-21T11:21:08.234913","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(y_pred, color=\"green\", label='Predicted values') # Random Forest prediction\nsns.kdeplot(y_test, color=\"red\", label='Actual values')\nplt.title(\"Relation between Predicted and Actual value (Random Forest Model)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forest Gived us 95%  so we will go with it","metadata":{}},{"cell_type":"markdown","source":"## 8- Testing\n* K fold Cross Validation\n* Testing For Random Forest Regressor","metadata":{"papermill":{"duration":0.193285,"end_time":"2021-11-21T11:21:55.758923","exception":false,"start_time":"2021-11-21T11:21:55.565638","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\ncv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\nmse = cross_val_score(LinearRegression(),X_test,y_test,cv=cv , scoring='neg_mean_squared_error')\nprint(mse)\nprint(' Mean of All Folds  is',mse.mean() )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(y_pred, color=\"green\", label='Predicted values') \nsns.kdeplot(y_test, color=\"red\", label='Actual values')\nplt.title(\"Relation between Predicted and Actual value (Random Forest Model)\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}